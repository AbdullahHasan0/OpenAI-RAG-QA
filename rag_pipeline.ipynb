{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdullahHasan0/OpenAI-RAG-QA/blob/main/rag_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fb875c",
      "metadata": {
        "id": "04fb875c"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cefe511d",
      "metadata": {
        "id": "cefe511d"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b290d32d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b290d32d",
        "outputId": "04372ff8-ab7d-454a-9884-10c0d9e09c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: PyPDF in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: ChromaDB in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->ChromaDB) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (0.21.4)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (33.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (3.11.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from ChromaDB) (4.25.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->ChromaDB) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->ChromaDB) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->ChromaDB) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->ChromaDB) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->ChromaDB) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->ChromaDB) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->ChromaDB) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->ChromaDB) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->ChromaDB) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->ChromaDB) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->ChromaDB) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->ChromaDB) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->ChromaDB) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->ChromaDB) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->ChromaDB) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->ChromaDB) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->ChromaDB) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->ChromaDB) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->ChromaDB) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->ChromaDB) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->ChromaDB) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->ChromaDB) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->ChromaDB) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->ChromaDB) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->ChromaDB) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->ChromaDB) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->ChromaDB) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->ChromaDB) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->ChromaDB) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->ChromaDB) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->ChromaDB) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->ChromaDB) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->ChromaDB) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->ChromaDB) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->ChromaDB) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->ChromaDB) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai langchain_community PyPDF ChromaDB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72418fc",
      "metadata": {
        "id": "b72418fc"
      },
      "source": [
        "\n",
        "\n",
        "* langchain → Core library for building RAG pipelines, chains, and LLM apps.\n",
        "\n",
        "* openai → For connecting to OpenAI APIs.\n",
        "\n",
        "* langchain_community → Extra integrations and community-built tools (like custom retrievers, connectors, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "527c860c",
      "metadata": {
        "id": "527c860c"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93009d31",
      "metadata": {
        "id": "93009d31"
      },
      "source": [
        "* from openai import OpenAI → Core OpenAI API client.\n",
        "\n",
        "* import os → Access environment variables, file paths, etc.\n",
        "\n",
        "* LangChain imports:\n",
        "\n",
        "    * OpenAIEmbeddings → Converts text into embeddings using OpenAI.\n",
        "\n",
        "    * OpenAI → LLM wrapper for OpenAI models.\n",
        "\n",
        "    * Chroma → Vector database for storing and searching embeddings.\n",
        "\n",
        "    * RecursiveCharacterTextSplitter → Splits documents into chunks intelligently with overlap.\n",
        "\n",
        "    * PyPDFLoader → Reads PDF files and converts to text.\n",
        "\n",
        "    * RetrievalQAWithSourcesChain → Builds a RAG pipeline that also provides source references.\n",
        "\n",
        "* from google.colab import files → For loading pdf interactively\n",
        "\n",
        "* import gradio → For interactive output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39fcc96",
      "metadata": {
        "id": "b39fcc96"
      },
      "source": [
        "## Function to connect OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2ee6f5af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ee6f5af",
        "outputId": "1dd36cb5-b7a2-457e-96cc-4fde534ef5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to OpenAI API...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2950313610.py:17: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  openai_client = OpenAI(openai_api_key=api_key)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to OpenAI API\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Replace 'YOUR_SECRET_NAME' with the actual name you gave your secret\n",
        "KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "\n",
        "def connect_openai(api_key):\n",
        "\n",
        "\n",
        "    # In Colab: store your OpenAI API key in Secrets or set it as an environment variable\n",
        "    api_key = api_key\n",
        "\n",
        "    if api_key:\n",
        "        print(\"Connecting to OpenAI API...\")\n",
        "        try:\n",
        "            openai_client = OpenAI(openai_api_key=api_key)\n",
        "            print(\"Connected to OpenAI API\")\n",
        "            return openai_client\n",
        "        except Exception as e:\n",
        "            print(f\"Error connecting to OpenAI: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"API key not found. Please add your OpenAI key in Colab Secrets or set OPENAI_API_KEY.\")\n",
        "        return None\n",
        "\n",
        "# Usage\n",
        "llm_client = connect_openai(KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b680a6",
      "metadata": {
        "id": "91b680a6"
      },
      "source": [
        "* Grabs your API key from Colab Secrets.\n",
        "* If the key exists → connects to OpenAI and returns the client.\n",
        "* If not → tells you to save the key first.\n",
        "* Handles errors safely so your notebook doesn’t crash.\n",
        "* Now llm_client is ready to use in your RAG pipeline.\n",
        "\n",
        "\n",
        "#### NOTE\n",
        "1. Go to Tools → Settings → Secrets (or search for “Secrets” in Colab).\n",
        "\n",
        "2. Add OPENAI_API_KEY as the key and your OpenAI key as the value.\n",
        "\n",
        "3. This avoids exposing keys in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b71b050",
      "metadata": {
        "id": "6b71b050"
      },
      "source": [
        "## Loading PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "293ae590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "293ae590",
        "outputId": "87aa396c-f928-4cac-f470-5977db9a8c1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8b138de-0659-453f-8cf8-b30a596c3774\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8b138de-0659-453f-8cf8-b30a596c3774\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Abdullah_Hasan_AI _RESUME.pdf to Abdullah_Hasan_AI _RESUME (3).pdf\n",
            "Loading PDF from Abdullah_Hasan_AI _RESUME (3).pdf...\n",
            "Loaded 2 pages from the PDF\n",
            "----------\n",
            "Syed Abdullah Hasan \n",
            "AI/ML Engineer   \n",
            "Karachi, Pakistan | Ph: +923228220707 | abdullahhasan1045@gmail.com | LinkedIn: Abdullah Hasan | \n",
            "Github: Abdullah Hasan \n",
            "  \n",
            "Professional Summary \n",
            "Aspiring AI/ML Engineer with hands-on experience in machine learning, deep learning, computer vision, \n",
            "NLP, and LLM-based applications. Skilled in Python, TensorFlow, PyTorch, Scikit-learn, and LangChain. \n",
            "Experienced in building end-to-end AI solutions including medical image classification, sentiment analysis, \n"
          ]
        }
      ],
      "source": [
        "def load_pdf_colab():\n",
        "    \"\"\"\n",
        "    Let the user pick a PDF from their computer in Colab,\n",
        "    then load it using PyPDFLoader.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    uploaded = files.upload()  # Opens file picker\n",
        "    if not uploaded:\n",
        "        print(\"No file uploaded.\")\n",
        "        return None\n",
        "\n",
        "    # Get the uploaded file name\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "    print(f\"Loading PDF from {file_path}...\")\n",
        "\n",
        "    try:\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        raw_documents = loader.load()\n",
        "        print(f\"Loaded {len(raw_documents)} pages from the PDF\")\n",
        "        print(\"-\"*10)\n",
        "        print(raw_documents[0].page_content[:500])\n",
        "        return file_path,raw_documents\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "file_path,raw_docs = load_pdf_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441e5d65",
      "metadata": {
        "id": "441e5d65"
      },
      "source": [
        "* Opens a file picker in Colab → you select the PDF.\n",
        "\n",
        "* Automatically gets the file name of the uploaded PDF.\n",
        "\n",
        "* Uses PyPDFLoader to read the PDF and split it into pages.\n",
        "\n",
        "* Prints number of pages and previews the first 500 characters.\n",
        "\n",
        "* Returns a list of pages (raw_documents) ready for chunking and embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62daa935",
      "metadata": {
        "id": "62daa935"
      },
      "source": [
        "## Splitting Document (Chunking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e75e68a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e75e68a8",
        "outputId": "2facbfd2-605e-4b45-f4de-cb03236c2aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting the loaded document into smaller chunks...\n",
            "Document split into 5 chunks.\n"
          ]
        }
      ],
      "source": [
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 150\n",
        "\n",
        "def split_documents(raw_documents, chunk_size=1000, chunk_overlap=150):\n",
        "    \"\"\"\n",
        "    Split PDF pages into smaller text chunks for embeddings.\n",
        "    \"\"\"\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "    print(\"\\nSplitting the loaded document into smaller chunks...\")\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "    documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "    if not documents:\n",
        "        raise ValueError(\"Error: Splitting resulted in zero documents\")\n",
        "\n",
        "    print(f\"Document split into {len(documents)} chunks.\")\n",
        "    return documents\n",
        "\n",
        "documents = split_documents(raw_docs, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00472586",
      "metadata": {
        "id": "00472586"
      },
      "source": [
        "* PDF pages are too big for embeddings → we split them into smaller chunks.\n",
        "\n",
        "* chunk_size=1000 → each chunk has up to 1000 characters.\n",
        "\n",
        "* chunk_overlap=150 → 150 characters overlap between chunks to keep context.\n",
        "\n",
        "* RecursiveCharacterTextSplitter → smartly splits text without breaking sentences awkwardly.\n",
        "\n",
        "* Returns a list of chunks ready for embeddings.\n",
        "\n",
        "* Prints how many chunks the document was split into."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0cc711bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cc711bf",
        "outputId": "00c58326-c25e-40b5-fdab-323f33082b2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-08-18T10:36:43+05:00', 'author': 'Ashir Afzal', 'moddate': '2025-08-18T10:36:43+05:00', 'source': 'Abdullah_Hasan_AI _RESUME (2).pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Syed Abdullah Hasan \\nAI/ML Engineer   \\nKarachi, Pakistan | Ph: +923228220707 | abdullahhasan1045@gmail.com | LinkedIn: Abdullah Hasan | \\nGithub: Abdullah Hasan \\n  \\nProfessional Summary \\nAspiring AI/ML Engineer with hands-on experience in machine learning, deep learning, computer vision, \\nNLP, and LLM-based applications. Skilled in Python, TensorFlow, PyTorch, Scikit-learn, and LangChain. \\nExperienced in building end-to-end AI solutions including medical image classification, sentiment analysis, \\ncontextual QA systems, and real-time computer vision pipelines. Passionate about applying technical skills \\nto real-world projects and growing in collaborative, high-performance teams. \\n  \\nProfessional Experience   \\nData Science Fellow – Bytewise Limited                                                                                                       \\nJune 2024 – Sep 2024  \\n• Expertise in data cleaning, scaling, encoding, and building various machine learning models,'),\n",
              " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-08-18T10:36:43+05:00', 'author': 'Ashir Afzal', 'moddate': '2025-08-18T10:36:43+05:00', 'source': 'Abdullah_Hasan_AI _RESUME (2).pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='June 2024 – Sep 2024  \\n• Expertise in data cleaning, scaling, encoding, and building various machine learning models, \\nincluding neural networks and CNNs. \\n• Partnered with teams to create innovative solutions for complex real-world challenges. \\n• Committed to advancing machine learning skills through practical experience and ongoing \\neducation. \\n• Fellow of the Month – June’24, Bytewise Limited  \\n  \\nAcademic Qualification   \\nUniversity Of Karachi - UBIT                                                                                                      2021 – 2024 \\n• Bachelors of Science in Computer Science  \\n  \\nCourse Certifications:  \\n• Certified Associate Data Scientist by DataCamp \\n• Data Manipulation with pandas by DataCamp \\n• Exploratory Data Analysis in Python \\n• Machine Learning from Udemy \\n• Data Science by Plus W 株式会社 \\n  \\nTechnical Skills: \\nProgramming & Libraries: Python, NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch, LangChain'),\n",
              " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-08-18T10:36:43+05:00', 'author': 'Ashir Afzal', 'moddate': '2025-08-18T10:36:43+05:00', 'source': 'Abdullah_Hasan_AI _RESUME (2).pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='• Data Science by Plus W 株式会社 \\n  \\nTechnical Skills: \\nProgramming & Libraries: Python, NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch, LangChain \\nML & AI Techniques: Regression, Classification, Clustering, CNNs, Transfer Learning, Attention \\nMechanisms, LLMs \\nData Handling: Data preprocessing, Feature engineering, SQL, NoSQL \\nVisualization: Matplotlib, Seaborn, Power BI \\nDeployment & Tools: Flask, Streamlit, Gradio, Jupyter Notebooks, Google Colab, Git \\nSoft Skills: Fast learner, proactive team player, growth-oriented mindset \\n  \\nProjects \\nBrain Hemorrhage Detection (Final Year Project) \\n• Built an end-to-end CNN pipeline using EfficientNetB2 for multiclass classification of 5 brain \\nhemorrhage types. \\n• Achieved 90%+ validation accuracy on RSNA_19 dataset using data augmentation and transfer \\nlearning. \\n• Preprocessed medical DICOM images with windowing techniques for model readiness.'),\n",
              " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-08-18T10:36:43+05:00', 'author': 'Ashir Afzal', 'moddate': '2025-08-18T10:36:43+05:00', 'source': 'Abdullah_Hasan_AI _RESUME (2).pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Student Performance Prediction System \\n• Developed a regression model to predict students’ math scores with an R² score of 88.76. \\n• Built a modular train-predict pipeline using one-hot encoding and feature standardization. \\n• Deployed a lightweight Flask API for real-time predictions. \\n \\nAmazon Review Sentiment Analysis \\n• Fine-tuned DistilRoBERTa for sentiment classification, achieving 94.8% accuracy. \\n• Preprocessed textual data (tokenization, lemmatization, stopword removal) and integrated \\nsummarization. \\n• Built a Gradio UI for real-time inference. \\n \\nLLM-Powered Contextual QA System \\n• Created a document-agnostic QA assistant with LangChain, Ollama, and LLaMA3 using RAG \\narchitecture. \\n• Implemented vector-based retrieval, dynamic prompt templates, and fallback handling for \\nunmatched queries. \\n \\nReal-Time Traffic Sign Detection (YOLOv8) \\n• Built and trained a YOLOv8 model for real-time detection and classification on a custom dataset.'),\n",
              " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-08-18T10:36:43+05:00', 'author': 'Ashir Afzal', 'moddate': '2025-08-18T10:36:43+05:00', 'source': 'Abdullah_Hasan_AI _RESUME (2).pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Real-Time Traffic Sign Detection (YOLOv8) \\n• Built and trained a YOLOv8 model for real-time detection and classification on a custom dataset. \\n• Deployed via Gradio for browser-based inference. \\n \\nContent-Based Anime Recommendation System \\n• Developed a recommendation engine using TF-IDF vectorization and cosine similarity. \\n• Cleaned and vectorized metadata to improve recommendation accuracy. \\n• Packaged into an interactive user application.')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c9bb3ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c9bb3ef",
        "outputId": "1f5b7061-02d1-4576-b0e6-72b464dacf97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example chunk: (Chunk 0) ---\n",
            "Syed Abdullah Hasan \n",
            "AI/ML Engineer   \n",
            "Karachi, Pakistan | Ph: +923228220707 | abdullahhasan1045@gmail.com | LinkedIn: Abdullah Hasan | \n",
            "Github: Abdullah Hasan \n",
            "  \n",
            "Professional Summary \n",
            "Aspiring AI/ML Engineer with hands-on experience in machine learning, deep learning, computer vision, \n",
            "NLP, and LLM-based applications. Skilled in Python, TensorFlow, PyTorch, Scikit-learn, and LangChain. \n",
            "Experienced in building end-to-end AI solutions including medical image classification, sentiment analysis, \n",
            "contextual QA systems, and real-time computer vision pipelines. Passionate about applying technical skills \n",
            "to real-world projects and growing in collaborative, high-performance teams. \n",
            "  \n",
            "Professional Experience   \n",
            "Data Science Fellow – Bytewise Limited                                                                                                       \n",
            "June 2024 – Sep 2024  \n",
            "• Expertise in data cleaning, scaling, encoding, and building various machine learning models,\n",
            "\n",
            "--- Metadata for Chunk 0 ---\n",
            "Abdullah_Hasan_AI _RESUME (2).pdf\n"
          ]
        }
      ],
      "source": [
        "## Let's display an example chunk\n",
        "print(\"\\n--- Example chunk: (Chunk 0) ---\")\n",
        "print(documents[0].page_content)\n",
        "print(\"\\n--- Metadata for Chunk 0 ---\")\n",
        "doc_source = documents[0].metadata['source'].split(\"/\")[-1]\n",
        "print(doc_source)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f90a405c",
      "metadata": {
        "id": "f90a405c"
      },
      "source": [
        "## Initializing Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0a4dcf26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4dcf26",
        "outputId": "116ba2fc-b2e5-4d4c-b63e-b4c479aa90aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing OpenAI Embeddings model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1923701173.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key=KEY)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI Embeddings model initialized.\n",
            "\n",
            "Creating ChromaDB vector store...\n",
            "ChromaDB vector store created with 5 items.\n"
          ]
        }
      ],
      "source": [
        "def create_vector_store(documents):\n",
        "    \"\"\"\n",
        "    Create embeddings for document chunks and store them in Chroma vector database.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Initializing OpenAI Embeddings model...\")\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=KEY)\n",
        "    print(\"OpenAI Embeddings model initialized.\")\n",
        "\n",
        "    print(\"\\nCreating ChromaDB vector store...\")\n",
        "    vector_store = Chroma.from_documents(documents=documents, embedding=embeddings)\n",
        "\n",
        "    # Verify the number of items in the store\n",
        "    vector_count = vector_store._collection.count()\n",
        "    print(f\"ChromaDB vector store created with {vector_count} items.\")\n",
        "\n",
        "    if vector_count == 0:\n",
        "        print(\"Warning: Vector store creation resulted in 0 items.\")\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "vector_store = create_vector_store(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67fcb8a2",
      "metadata": {
        "id": "67fcb8a2"
      },
      "source": [
        "* Embeddings: Converts each chunk of text into a numeric vector using OpenAIEmbeddings.\n",
        "\n",
        "* Vector Store (ChromaDB): Stores all embeddings for fast semantic search/retrieval.\n",
        "\n",
        "* _collection.count() → checks how many vectors were stored.\n",
        "\n",
        "* Returns vector_store → now you can use it for RAG queries.\n",
        "\n",
        "* Prints messages so you know each step is working."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b251152",
      "metadata": {
        "id": "4b251152"
      },
      "source": [
        "## Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "189b500f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "189b500f",
        "outputId": "ff66cd7d-3c74-460f-adca-d6f2a29b12d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Similarity Search in vector store ---\n",
            "Searching for documents similar to: 'what is sick leave policy'\n",
            "Found 2 similar documents.\n",
            "\n",
            "--- Document 1 ---\n",
            "Content snippet: • Data Science by Plus W 株式会社 \n",
            "  \n",
            "Technical Skills: \n",
            "Programming & Libraries: Python, NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch, LangChain \n",
            "ML & AI Techniques: Regression, Classification, Clustering, CNNs, Transfer Learning, Attention \n",
            "Mechanisms, LLMs \n",
            "Data Handling: Data preprocessing, Feature engineering, SQL, NoSQL \n",
            "Visualization: Matplotlib, Seaborn, Power BI \n",
            "Deployment & Tools: Flask, Streamlit, Gradio, Jupyter Notebooks, Google Colab, Git \n",
            "Soft Skills: Fast learner, proactive team player, growth-oriented mindset \n",
            "  \n",
            "Projects \n",
            "Brain Hemorrhage Detection (Final Year Project) \n",
            "• Built an end-to-end CNN pipeline using EfficientNetB2 for multiclass classification of 5 brain \n",
            "hemorr...\n",
            "Source: Abdullah_Hasan_AI _RESUME (2).pdf\n",
            "\n",
            "--- Document 2 ---\n",
            "Content snippet: Syed Abdullah Hasan \n",
            "AI/ML Engineer   \n",
            "Karachi, Pakistan | Ph: +923228220707 | abdullahhasan1045@gmail.com | LinkedIn: Abdullah Hasan | \n",
            "Github: Abdullah Hasan \n",
            "  \n",
            "Professional Summary \n",
            "Aspiring AI/ML Engineer with hands-on experience in machine learning, deep learning, computer vision, \n",
            "NLP, and LLM-based applications. Skilled in Python, TensorFlow, PyTorch, Scikit-learn, and LangChain. \n",
            "Experienced in building end-to-end AI solutions including medical image classification, sentiment analysis, \n",
            "contextual QA systems, and real-time computer vision pipelines. Passionate about applying technical skills \n",
            "to real-world projects and growing in collaborative, high-performance teams. \n",
            "  \n",
            "Profession...\n",
            "Source: Abdullah_Hasan_AI _RESUME (2).pdf\n"
          ]
        }
      ],
      "source": [
        "def test_similarity_search(vector_store, query, top_k=2):\n",
        "    \"\"\"\n",
        "    Test the vector store by finding documents similar to a query.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Testing Similarity Search in vector store ---\")\n",
        "    print(f\"Searching for documents similar to: '{query}'\")\n",
        "\n",
        "    try:\n",
        "        similar_docs = vector_store.similarity_search(query, k=top_k)\n",
        "        print(f\"Found {len(similar_docs)} similar documents.\")\n",
        "\n",
        "        for i, doc in enumerate(similar_docs):\n",
        "            print(f\"\\n--- Document {i+1} ---\")\n",
        "            content_snippet = doc.page_content[:700].strip() + \"...\"  # first 700 characters\n",
        "            source = doc.metadata.get('source', 'Unknown').split(\"/\")[-1]\n",
        "            print(f\"Content snippet: {content_snippet}\")\n",
        "            print(f\"Source: {source}\")\n",
        "\n",
        "        return similar_docs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while searching for similar documents: {e}\")\n",
        "        return []\n",
        "\n",
        "test_docs = test_similarity_search(vector_store, \"what is sick leave policy\", top_k=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57aabc08",
      "metadata": {
        "id": "57aabc08"
      },
      "source": [
        "* Lets you query your vector store with a question.\n",
        "\n",
        "* similarity_search() → finds the top k chunks most relevant to your query.\n",
        "\n",
        "* Prints the first 700 characters of each chunk as a preview.\n",
        "\n",
        "* Prints the source filename for reference.\n",
        "\n",
        "* Returns the list of similar documents so you can use them in a RAG chain or further processing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd49256a",
      "metadata": {
        "id": "bd49256a"
      },
      "source": [
        "## Building & Testing The RAG CHAIN USING LANGCHAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "18a67e5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18a67e5b",
        "outputId": "57c1bec7-f8c9-44fa-d062-cf18f8eba814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieval configured successfully from vector store.\n",
            "OpenAI LLM successfully configured.\n",
            "RetrievalQAWithSourcesChain created\n"
          ]
        }
      ],
      "source": [
        "def create_qa_chain(vector_store, temperature=0, k=2):\n",
        "    \"\"\"\n",
        "    Create a RAG (Retrieval-Augmented Generation) QA chain using OpenAI LLM and a vector store.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Configure retriever\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": k})\n",
        "    print(\"Retrieval configured successfully from vector store.\")\n",
        "\n",
        "    # Step 2: Configure LLM\n",
        "    llm = OpenAI(temperature=temperature, openai_api_key=KEY)\n",
        "    print(\"OpenAI LLM successfully configured.\")\n",
        "\n",
        "    # Step 3: Create RetrievalQAWithSourcesChain\n",
        "    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=False,\n",
        "        verbose=True\n",
        "    )\n",
        "    print(\"RetrievalQAWithSourcesChain created\")\n",
        "\n",
        "    return qa_chain\n",
        "\n",
        "qa_chain = create_qa_chain(vector_store, temperature=0, k=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae78a7f",
      "metadata": {
        "id": "7ae78a7f"
      },
      "source": [
        "* Retriever: Gets the top k relevant chunks from the vector store for any query.\n",
        "\n",
        "* LLM: OpenAI model that generates answers using the retrieved chunks.\n",
        "\n",
        "* RAG Chain: Combines retriever + LLM → now your QA system can answer questions with context from your PDF.\n",
        "\n",
        "* return_source_documents=False → doesn’t return full source docs in output (optional).\n",
        "\n",
        "* verbose=True → prints what’s happening internally for debugging.\n",
        "\n",
        "* Returns qa_chain → ready to answer questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "54b0d066",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54b0d066",
        "outputId": "cfe14e95-2d99-4bae-ae8e-a0d8594a8007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing the Full RAG Chain ---\n",
            "Query: Information about sick leaves\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "--- Answer ---\n",
            " The professional experience includes sick leaves.\n",
            "\n",
            "\n",
            "--- Sources ---\n",
            "Abdullah_Hasan_AI _RESUME (2).pdf\n"
          ]
        }
      ],
      "source": [
        "def test_rag_chain(qa_chain, query):\n",
        "    \"\"\"\n",
        "    Run a query through the RAG QA chain and display answer and sources.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Testing the Full RAG Chain ---\")\n",
        "    print(f\"Query: {query}\")\n",
        "\n",
        "    try:\n",
        "        result = qa_chain.invoke({\"question\": query})\n",
        "\n",
        "        print(\"\\n--- Answer ---\")\n",
        "        print(result.get(\"answer\", \"No answer generated.\"))\n",
        "\n",
        "        print(\"\\n--- Sources ---\")\n",
        "        print(result.get(\"sources\", \"No sources found.\"))\n",
        "\n",
        "        # Optional: show source document snippets if available\n",
        "        if \"source_documents\" in result and result[\"source_documents\"]:\n",
        "            print(\"\\n--- Source Document Details ---\")\n",
        "            for i, doc in enumerate(result[\"source_documents\"]):\n",
        "                content_snippet = doc.page_content[:250].strip() + \"...\"\n",
        "                print(f\"Doc {i+1}: {content_snippet}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "result = test_rag_chain(qa_chain, \"Information about sick leaves\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4891f63",
      "metadata": {
        "id": "e4891f63"
      },
      "source": [
        "* Sends your query (\"Information about sick leaves\") to the RAG QA chain.\n",
        "\n",
        "* Prints the generated answer from OpenAI.\n",
        "\n",
        "* Prints source references (if available).\n",
        "\n",
        "* Optionally shows first 250 characters of the source documents for context.\n",
        "\n",
        "* Handles errors safely → notebook won’t crash if something goes wrong.\n",
        "\n",
        "* Returns the result dictionary → you can access answer, sources, or source_documents programmatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "89c0fc9b",
      "metadata": {
        "id": "89c0fc9b"
      },
      "outputs": [],
      "source": [
        "def ask_document(user_query):\n",
        "\n",
        "    \"\"\"Processes the user query using the RAG chain and returns formatted results\"\"\"\n",
        "\n",
        "    print(f\"\\nProcessing Gradio query: '{user_query}'\")\n",
        "    if not user_query or user_query.strip() == \"\":\n",
        "        print(\"Empty query received. Returning prompt for valid input.\")\n",
        "        return \"Please enter a valid query.\"\n",
        "\n",
        "    try:\n",
        "        result = qa_chain.invoke({\"question\": user_query})\n",
        "\n",
        "        answer = result.get(\"answer\", \"I couldn't find an answer in the provided document.\")\n",
        "        sources = result.get(\"sources\", \"No specific sources identified.\")\n",
        "\n",
        "        if sources == file_path:\n",
        "            sources = f\"Retrieved from: {file_path}\"\n",
        "\n",
        "        elif isinstance(sources, list):\n",
        "            sources = \", \".join(list(set(sources)))\n",
        "\n",
        "        print(f\" --> Answer generated: {answer[:100].strip()}...\")\n",
        "        print(f\" --> Sources Identified: {sources}\")\n",
        "\n",
        "        return answer.strip(), sources\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing query: {e}\")\n",
        "        return \"An error occurred while processing your query.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63ca8cd6",
      "metadata": {
        "id": "63ca8cd6"
      },
      "source": [
        "## Creating Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6b4a4ec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "6b4a4ec6",
        "outputId": "e9df837c-c788-4eca-dd42-2451e1f08ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setting up Gradio Interface...\n",
            "Gradio Interface setup complete. Launching the app...\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b2c432bdde5a7f251.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b2c432bdde5a7f251.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def launch_gradio_interface(qa_chain):\n",
        "    \"\"\"\n",
        "    Launch a Gradio interface to ask questions to the HR document QA system.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nSetting up Gradio Interface...\")\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Ocean(), title=\"Document QA Assistant\") as demo:\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            ## Document QA Assistant\n",
        "            Ask questions about your HR document and get answers with sources.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Input Component\n",
        "        question_input = gr.Textbox(\n",
        "            label=\"Ask a question about the document\",\n",
        "            placeholder=\"Type your question here...\",\n",
        "            lines=2\n",
        "        )\n",
        "\n",
        "        # Output Components\n",
        "        with gr.Row():\n",
        "            answer_output = gr.Textbox(\n",
        "                label=\"Answer\",\n",
        "                placeholder=\"The answer will be displayed here...\",\n",
        "                lines=4,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            sources_output = gr.Textbox(\n",
        "                label=\"Sources\",\n",
        "                placeholder=\"The sources will be displayed here...\",\n",
        "                lines=2,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "        # Buttons\n",
        "        with gr.Row():\n",
        "            submit_button = gr.Button(\"Submit\", variant=\"primary\")\n",
        "            clear_button = gr.ClearButton(\n",
        "                components={question_input, answer_output, sources_output},\n",
        "                value=\"Clear All\"\n",
        "            )\n",
        "\n",
        "\n",
        "        # Connect submit button to QA function\n",
        "        submit_button.click(\n",
        "            fn=ask_document,\n",
        "            inputs=question_input,\n",
        "            outputs=[answer_output, sources_output]\n",
        "        )\n",
        "\n",
        "    print(\"Gradio Interface setup complete. Launching the app...\")\n",
        "    demo.launch()\n",
        "\n",
        "launch_gradio_interface(qa_chain)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}